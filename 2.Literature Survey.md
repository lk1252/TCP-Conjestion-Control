#LITERATURE REVIEW


There are two ways of solving the network congestion problem namely, end-to-end and network side approach. The end-to-end focuses on terminal congestion control whereas the network side focuses on data stream scheduling and line management on forwarding nodes. The current level of development in the standard network algorithm is totally insufficient to
 
meet the growing network demand. A SDN approach is required to find a solution to the network congestion. These policies are used to specify what statistics need to be collected, what the target operational goal is (e.g., to reduce flow completion times, or to maximize the utilization of specific link that is given), the constraints need to be satisfied. As part of policies, the operator can actually define some set of preconditions that has to be satisfied before modifications are made to specific TCP sessions. This creates an  environment that the operator can use to modify TCP without the risk of making the network unstable.
SDN’s is a necessity to solve TCP congestion problem. These are some of the reasons that explain why:
The increase of network intelligence and resource sharing in carrier networks.
A lot of the information is stored and processed on computers out on the carrier networks like cloud, data centres, etc. This calls for the network managers/operators to use SDN technologies to control their networks and resources in a much efficient manner.
The need for network programmability.
Network operators and service providers need more intelligent control systems to directly control the behaviour of many routers and switches.
Emerging service-aware networking in networks.
As customers want to establish their specific purpose services (e.g., on-demand  “express lanes” with guaranteed QoS for voice and data traffic, that is, time-sensitive), network operators/service providers should provide a certain method for interaction between the services and network infrastructure and then the services should be securely isolated from other existing customers' traffic.
High complexity of operations and management in networks.
As network complexity more increases in networks, network operators want to reduce management and operation complexity with software-defined networking rather than configured networks.


In the standard IP network architecture, both the control planes and forwarding planes which are highly integrated, and also where the network is difficult to extend and customize.
It has a long technology update cycle and is too dependent on network equipment manufacturers. Also, the increasing in complex network environment makes it difficult to develop the network and make innovations related to the hardware of physical devices or software of related protocols and performances. Programmable models and code which allow the data transmission from the network to the application which are and whenever needed. SDN will separate the network control and forwarding functions, which enables the network that can be directly programmable, dynamic, and manageable The separation of the control plane and data plane allows the core technology OpenFlow to realize the flexible control of the network traffic, making the network more intelligent, and which will provide a better platform for network application innovation and much more .
 
In this paper, Comparing these with the existing literature survey, this paper has these following major contributions:


A survey of congestion control in the IP network is now presented. In the standard networks, the underlying network and flow information are unknown. It should increase or reduce the size of the congestion window so that to adjust to the changes of traffic, while a SDN can relieve the network congestion problem more efficiently. So that, we will propose a software-defined congestion control algorithm for an IP network. The type of data flow in the IP network has to be taken into account. The difference between TCP & UDP will be pointed out. Based on the different characteristics of TCP & UDP, we will propose a new method in judging congested nodes.

The simulation of this algorithm is very comprehensively explained. We consider the rate of packet loss and optimization of link utilization. This simulation shows that the proposed algorithm achieves a network congestion control and also optimizes the link utilization.


Congestion cause high number of packet loss and lower network performance. Congestion in SDN should be avoided because it might cause severe network performance. One of the effects of congestion is the increase in the number of packet loss. High number of this packet loss causes the node to retransmit the data and this will contribute to low packet delivery ratio (PDR). The time for packet to reach at destination node will also be delayed causing end-to-end delay to increase and the throughput to decrease. Hence, the data might not be valid once it retransmit to the destination node due to high latency occurs. Therefore, avoiding congestion can reduce the aforementioned effects and improve the overall network performance.

Congestion reduces the Quality of Service in SDN. Large number of users are sending data simultaneously to the SDN controller, this will not only cause high buffer usage but also cause TCP congestion. This is because of the high redundancy in packet transmission will increase the traffic and this might lead to a possibility of buffer overflow that can lead to congestion.  Thus, the congestion can affect to packet loss rate increase, delay increase, low throughput, so cannot provide high QoS to users, user may experience interruption in the communication especially in the real- time applications. In addition, huge number of packets will be wasted in sending the redundant information data. Therefore there is need to find a better way to improve packet delay ratio, throughput while reducing packet loss rate and latency.
Lack of congestion control technique in SDN.


SDN will only deal with large amount of data information which cannot be afforded due to large amount of congestion in network. This is because the congestion can cause high packet loss rates and may cause buffer overflow. Therefore, resolution for congestion control mechanisms need to maintain and control network congestion efficiently in SDN.
 
We shall survey and study about few TCP methods. The TCP Reno method has few drawbacks which can be overcome by a methodology called TCP Veno. It refines the multiplicative decrease algorithm of TCP Reno by adjusting the slow-start threshold according to the perceived network congestion level rather than a fixed drop factor and it refines the linear increase algorithm so that the connection can stay longer in an operating region in which the network bandwidth is fully utilized. This Veno is useful for wireless networks but Reno stands at the top in being the most used TCP algorithm. The Veno however is desirable for its deployability, flexibility and compatability.


According to the Cisco Visual Networking Index (VNI) , in 2016 video content with a duration of 1.2 million minutes will cross the global IP networks every second. Many contemporary transmission streaming in the Internet for long duration are highly inflexible regarding their data rate consumption will be so fast, which particularly holds for multimedia streams. These streaming’s will demand for a reliable lower data rate bound and will increase their sending rate up to a specific value. The scheme employed in this paper was to avoid congestion altogether before it happened by developing a signaling protocol which is applied in the controller plane of SDN to provide a network rate control service. In case of unavailability of this service a traditional scheme can be used as a fallback.


Clusters of independent processors are highly used for parallelization in High Performance Computing environment. Cloud technology uses an unique infrastructure that involves in large number of computers which are connected through a network. Cloud service allows users to provision resources easily and quickly by paying only for their usage  of the resources. Cloud computing offers the benefits of utility and elastic pool of resources, plus it eliminates the initial cluster setup cost and time . However, The performance is poor due to network, virtualization overheads that causes the performance degradation, Qos, and also the noisy neighbor issues which are some of the challenges for execution of  real-time, high performance, tightly coupled, parallel applications on Cloud. Centralized programmable network control plane architectures with multi-protocol low latency plugins will replace todays proprietary network architectures for hyper-scale infrastructures and cloud computing architectures are used for high performance computing. experimental data proved that SR-IOV provides a good solution for high performance I/O virtualization, without sacrificing migration. One of the most crucial building blocks of the network is the mechanism for the resource sharing and the congestion that is being controlled on the internet. Congestion can also be defined as a network state in which the whole demand for resources, e.g. bandwidth, among the users competing, will exceeds the available capacity leading to packet or information loss and results in packet retransmissions .At the time of congestion in a computer network where there will be lots of simultaneous increase in queuing delay, packet loss and number of packet re-transmissions. In other words congestion refers to a loss of network performance when a network is heavily loaded. 


Source based congestion control methods are reactive in nature i.e. source host reacts after getting congestion signals from the networks, by reducing its transmission speed. TCP will use implicit congestion signals such as delay or packet loss or the combination of both. Based on the types of signals, source based approaches are categorized as: hybrid approach, delay based approach and loss based approach Router based congestion
 
control methods are proactive in nature. Router will continuously measure the traffic that is being loaded and check if there was any symptoms of traffic overload which causes congestion, it will send a signal to source host so that in can slow down its transmission speed before congestion occurs. These router based methods will send incipient congestion signal by marking packets with a mark probability. Based on the mark probability calculation criteria router based methods are categorized as Queue length based, Rate based and Hybrid approach.

As CPU computing capability continues to scale with Moore’s Law, it is expected to run more VMs on a single platform. SR-IOV-based I/O virtualization serves is a good base to meet up with the scalability requirement. It’s believed that SR-IOV-based I/O virtualization provides a good platform for further study of I/O virtualization, such as video and audio sharing.


SDN is solving most of the problems at real-time by providing the required network programmability, flexibility and centralization. SDN will separate the path and control the logic which are called data plane and control plane. For fast growing adaptation we will require various SDN applications running on control plane such as router, firewall and load balancer. SDN has separated control logic from the forwarding logic.. Routers are the essential part of any network. For Software Defined Networking to gain momentum, we need different network applications. Static Routing is suitable for small networks and is easier to implement than dynamic router but isn’t suitable for larger networks.

Using network virtualization, users of these network resources, i.e., service providers (SPs), can also be separated from the owners with the network resources, i.e., infrastructure providers (InPs). In this case, SPs will not be required to own the network infrastructure, and they can also focus on providing some network services without constructing or managing the network infrastructure. By network virtualization, different kinds of network  components can be replaced with common servers, and a network operator can flexibly cope with the sudden change in demand for specific functions, so we can expect to reduce the operational cost and amount of consumed electrical power through the aggregation of various physical network components. a much larger effect of network virtualization is separation of the use and ownership of network resources. In other words, we can use network resources more flexibly because the granularity of the utilization unit of a network resource becomes finer by providing various network functions via software. As a result, network providers are separated into service providers (SPs) and infrastructure providers (InPs). it is important to suitably define a management model of network resources required to trade them between InPs and SPs.
