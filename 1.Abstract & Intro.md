#ABSTRACT

The recent evolution around network needs has driven us to re-evaluate the standard architecture. The fast evolution of computer networks, increase within the variety of web users, and recognition of multimedia system applications created the congestion control problem. Congestion control could be a key factor about guaranteeing network stability and strength. once the underlying network and flow data square measure unknown, the transmission communication protocol (TCP) should increase or cut back the scale of the congestion window to regulate to the changes of traffic within the web Protocol (IP) network.
With a software defined approach we are able to relieve the matter of network congestion efficiently. During this paper, we tend to outline associated compare four completely different congestion control algorithms over an IP network to efficiently cut back and control the communication protocol congestion.

#INTRODUCTION

Recently, the increase of internet traffic due to the addiction of mobile devices, IPTV, cloud services and server virtualization are becoming more complicated for a standard architecture network to handle high amount of traffic. In standard network, device such as router, firewall and switch has their own control plane and data plane. And hence, the network cannot be handle higher user package transfer because the forward plane and control plane are in the same system. Thus, more and more flexible and dynamic network is required to manage traffic.
The communication networks is having a rapid growth and getting to be more complex to be manage. Hence, Software Defined Network is a best approach to be used in computer networking which separates data plane and control plane combined with centralized controller to allow the internet operator to program and to forward he packets. One of the major downside of congestion in network is the reduction of Quality of Service (QoS) that cause a large amount of loss in several network aspects which leads to congestion in network traffic.

 
There are two ways in solving the network congestion. The first is end- to-end approach, in which it is focused on the mechanism of terminal congestion. The second is network side approach, in here it is achieved by means of data stream scheduling and line management on the forwarding nodes.
Many Researchers have surveyed significant investigation and exploration and have to put forward a lot of improvements. Let’s Say, that the most recent versions of the four different sorts of communication algorithms are Reno, BIC, Cubic and H-TCP which have been achieved optimization by packet loss judgment, bandwidth prediction, homogeneous compensation mechanism and time delay compensation respectively.
The approximate limit of the largest transfer rate of each data flow can effectively reduce network congestion and packet loss. Whatsoever, previous studies reported that when the underlying information flow are unknown, TCP should increase or reduce the size of congestion window to adjust the network traffic. This highlighted the standard IP network lacks the direct control of forwarding queue and cannot be guaranteed for link utilization and quality of service. We have considered this in our research by stating the problem statement with the solution for the network congestion problem by defining, comparing and implementing the four algorithms, Say… in a virtualization technology (Mininet) to simulate the controlling of TCP congestion at the transfer of network packets(in a congested environment).

Reno are some of the Classical models used in controlling congestion of network traffic which typically have slow starting throughput and then increases gradually until it stays stable. Again, it is decreased as soon as it reaches transfer encounters congestion, then it rises again gradually. The window size is increased by adding some constant values. Reno uses a multiplicative algorithm for the reduction in window size and it is one of the most widely used or deployed algorithm. BIC uses a unique growth of window size which on packet loss, reduces the window size by a multiplicative factor. The window size is used as a parameter just before and after the reduction for a binary search for the new window size. BIC was one of the traditional algorithms in the Linux kernel and still being used. CUBIC is a less aggressive likely of BIC which don’t take as much of throughput from competing TCP flows as its predecessor. H-TCP is also an algorithm developed by a famous institute called the Hamilton Institute for transmissions that recover more quickly after a congestion event and is designed for links with high bandwidth and RTT.
